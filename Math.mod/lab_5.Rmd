---
title: "Упражнение_5"
author: "Aigunov"
date: "15 03 2021"
output: html_document
---

```{r setup, include=FALSE}
library('MASS')
library('GGally')
library('boot')
knitr::opts_chunk$set(echo = TRUE)
my.seed <- 1
```
```{r}
DF.Boston <- subset(Boston, select = c(crim, zn, rm, chas))
head(DF.Boston)
summary(DF.Boston)
DF.Boston$chas <- as.factor(DF.Boston$chas)
```
```{r}
#графики разброса
ggpairs(DF.Boston[],ggplot2::aes(color = chas))
#только crim ~ chas
plot(DF.Boston$chas, DF.Boston$crim,
     xlab = 'chas', ylab = 'crim', pch = 21,
     col = rgb(0,0,1,alpha = 0.4), bg = rgb(0,0,1, alpha = 0.4))
```

#Метод проверочной выборки

Он состоит в том, что мы отбираем одну тестовую выборку и будем считать на ней ошибку модели.

```{r}
n <- nrow(DF.Boston) #общее число наблюдений
train.precent <- 0.5
set.seed(my.seed)
inTrain <- sample(1:n, n * train.precent)
#Фактические значения Y на тестовой выборке
y.test.fact <- DF.Boston$crim[-inTrain]
#разными цветами обучающую и тестовую

#plot(DF.Boston$chas[inTrain], DF.Boston$crim[inTrain],
#     xlab = 'chas', ylab = 'crim', pch = 21,
#     col = rgb(0, 0, 1, alpha = 0.4), bg = rgb(0, 0, 1, alpha = 0.4))
#points(DF.Boston$chas[-inTrain], DF.Boston$crim[-inTrain],
#       pch = 21, col = rgb(1, 0, 0, alpha = 0.4), 
#       bg = rgb(1, 0, 0, alpha = 0.4))
#legend('topright', 
#       pch = c(16, 16), col = c('blue', 'red'), legend = c('test', 'train'))


#ggplot(DF.Boston, aes(x = chas, y = crim)) + 
#  geom_boxplot(outlier.shape=NA) + #avoid plotting outliers twice
#  geom_jitter(position = position_jitter(width = .1, height = 0))
DF.Boston$Выборка <- 1
DF.Boston$Выборка[inTrain] <- 2
DF.Boston$Выборка <- as.factor(DF.Boston$Выборка)
levels(DF.Boston$Выборка) <- c('test','train')
ggplot(
  DF.Boston, aes(x = chas, y = crim)) + 
  geom_boxplot(outlier.shape=NA) + 
  geom_jitter(aes(bg = Выборка),position = position_jitter(width = .1, height = 0),
  pch = 21, col = rgb(0, 0, 1, alpha = 0.4)
  )

```
#Построим модели для проверки точности.

Линейная модель

```{r}
attach(DF.Boston)
#подгонка модели на обучающей выборке
fit.lm.1 <- lm(crim ~ rm + zn, subset = inTrain)
# прогноз на тестовую
y.test.lm.1 <- predict(fit.lm.1, DF.Boston[-inTrain, ])
#MSE на тестовой выборке
MSE.lm.1 <- mean((y.test.fact - y.test.lm.1)^2)
detach(DF.Boston)
MSE.lm.1
```
Линейная модель с фиктивной переменной

```{r}
attach(DF.Boston)
#подгонка модели на обучающей выборке
fit.lm.1_1 <- lm(crim ~ rm + zn + chas, subset = inTrain)
# прогноз на тестовую
y.test.lm.1_1 <- predict(fit.lm.1_1, DF.Boston[-inTrain, ])
#MSE на тестовой выборке
MSE.lm.1_1 <- mean((y.test.fact - y.test.lm.1_1)^2)
detach(DF.Boston)
MSE.lm.1_1

```


Квадратичная модель
```{r}
attach(DF.Boston)
# подгонка модели на обучающей выборке
fit.lm.2 <- lm(crim ~ poly(zn, 2) + poly(rm, 2), subset = inTrain)
# прогноз на тестовую
y.test.lm.2 <- predict(fit.lm.2, DF.Boston[-inTrain, ])
# считаем MSE на тестовой выборке
MSE.lm.2 <- round(mean((y.test.fact - y.test.lm.2)^2), 2)
detach(DF.Boston)
MSE.lm.2
```

Квадратичная модель с фиктивной переменной

```{r}
attach(DF.Boston)
# подгонка модели на обучающей выборке
fit.lm.2_1 <- lm(crim ~ poly(zn, 2) + poly(rm, 2) + chas, subset = inTrain)
# прогноз на тестовую
y.test.lm.2_1 <- predict(fit.lm.2_1, DF.Boston[-inTrain, ])
# считаем MSE на тестовой выборке
MSE.lm.2_1 <- round(mean((y.test.fact - y.test.lm.2_1)^2), 2)
detach(DF.Boston)
MSE.lm.2_1
```

Кубическая модель
```{r}
attach(DF.Boston)
# подгонка модели на обучающей выборке
fit.lm.3 <- lm(crim ~ poly(zn, 3) + poly(rm, 3), subset = inTrain)
# прогноз на тестовую
y.test.lm.3 <- predict(fit.lm.3, DF.Boston[-inTrain, ])
# считаем MSE на тестовой выборке
MSE.lm.3 <- round(mean((y.test.fact - y.test.lm.3)^2), 2)
detach(DF.Boston)
MSE.lm.3
```
Кубическая модель с фиктивной переменной

```{r}
attach(DF.Boston)
# подгонка модели на обучающей выборке
fit.lm.3_1 <- lm(crim ~ poly(zn, 3) + poly(rm, 3) + chas, subset = inTrain)
# прогноз на тестовую
y.test.lm.3_1 <- predict(fit.lm.3_1, DF.Boston[-inTrain, ])
# считаем MSE на тестовой выборке
MSE.lm.3_1 <- round(mean((y.test.fact - y.test.lm.3_1)^2), 2)
detach(DF.Boston)
MSE.lm.3_1

```




#Перекрёстная проверка по отдельным наблюдениям (LOOCV)

Это самый затратный в вычислительном плане метод, но и самый надёжный в плане оценки ошибки вне выборки. Попробуем применить его к линейной модели.

```{r}
# подгонка линейной модели на обучающей выборке
fit.glm <- glm(crim ~ chas, data = DF.Boston)
# считаем LOOCV-ошибку
cv.err <- cv.glm(DF.Boston, fit.glm)
# результат: первое число -- по формуле LOOCV-ошибки
#  второе -- с поправкой на смещение
cv.err$delta[1]
```

Теперь оценим точность полиномиальных моделей, меняя степень, в которой стоит регрессор.

```{r}
# вектор с LOOCV-ошибками
cv.err.loocv <- rep(0, 5)
# имена элементов вектора
names(cv.err.loocv) <- 1:5
# цикл по степеням полиномов
for (i in 1:5) {
  # оценка модели
  fit.glm <- glm(crim ~ poly(zn, i) + poly(rm, i), data = DF.Boston)
  # расчёт ошибки
  cv.err.loocv[i] <- cv.glm(DF.Boston, fit.glm)$delta[1]
}
# результат
cv.err.loocv

```
```{r}
# вектор с LOOCV-ошибками
cv.err.loocv_1 <- rep(0, 5)
# имена элементов вектора
names(cv.err.loocv_1) <- 1:5
# цикл по степеням полиномов
for (i in 1:5) {
  # оценка модели
  fit.glm <- glm(crim ~ poly(zn, i) + poly(rm, i) + chas, data = DF.Boston)
  # расчёт ошибки
  cv.err.loocv_1[i] <- cv.glm(DF.Boston, fit.glm)$delta[1]
}
# результат
cv.err.loocv_1
```


#k-кратная перекрёстная проверка

K-кратная кросс-валидация – компромисс между методом проверочной выборки и LOOCV. Оценка ошибки вне выборки ближе к правде, по сравнению с проверочной выборкой, а объём вычислений меньше, чем при LOOCV. Проведём 10-кратную кросс-валидацию моделей разных степеней.

```{r}
# оценим точность полиномиальных моделей, меняя степень

# вектор с ошибками по 5-кратной кросс-валидации

cv.err.k.fold.5 <- rep(0, 5)
# имена элементов вектора
names(cv.err.k.fold.5) <- 1:5

# цикл по степеням полиномов
for (i in 1:5) {
  # оценка модели
  fit.glm <- glm(crim ~ poly(zn, i) + poly(rm, i), data = DF.Boston)
  # расчёт ошибки
  cv.err.k.fold.5[i] <- cv.glm(DF.Boston, fit.glm, K = 5)$delta[1]
}

# результат
cv.err.k.fold.5

cv.err.k.fold.5_1 <- rep(0, 5)
# имена элементов вектора
names(cv.err.k.fold.5_1) <- 1:5

# цикл по степеням полиномов
for (i in 1:5) {
  # оценка модели
  fit.glm <- glm(crim ~ poly(zn, i) + poly(rm, i) + chas, data = DF.Boston)
  # расчёт ошибки
  cv.err.k.fold.5_1[i] <- cv.glm(DF.Boston, fit.glm, K = 5)$delta[1]
}

# результат
cv.err.k.fold.5_1

# вектор с ошибками по 10-кратной кросс-валидации
cv.err.k.fold.10 <- rep(0, 5)
# имена элементов вектора
names(cv.err.k.fold.10) <- 1:5

# цикл по степеням полиномов
for (i in 1:5) {
  # оценка модели
  fit.glm <- glm(crim ~ poly(zn, i) + poly(rm, i), data = DF.Boston)
  # расчёт ошибки
  cv.err.k.fold.10[i] <- cv.glm(DF.Boston, fit.glm, K = 10)$delta[1]
}

# результат
cv.err.k.fold.10

cv.err.k.fold.10_1 <- rep(0, 5)
# имена элементов вектора
names(cv.err.k.fold.10_1) <- 1:5

# цикл по степеням полиномов
for (i in 1:5) {
  # оценка модели
  fit.glm <- glm(crim ~ poly(zn, i) + poly(rm, i) + chas, data = DF.Boston)
  # расчёт ошибки
  cv.err.k.fold.10_1[i] <- cv.glm(DF.Boston, fit.glm, K = 10)$delta[1]
}

# результат
cv.err.k.fold.10_1
```

Объединим все ошибки в одну таблицу и отсортируем её по возрастанию MSE:

```{r}
# записываем все ошибки в таблицу
df.MSE <- data.frame(Модель = c('Линейная', 'Полином 2 степени',
                                'Полином 3 степени',
                              rep(paste('Полином', 1:5, 'степени'), 3)),
          Проверка.точности = c(rep('Проверочная выборка 50%', 3),
                                rep('LOOCV', 5),
                                rep('Кросс-валидация, k = 5', 5),
                                rep('Кросс-валидация, k = 10', 5)),
          MSE = round(c(MSE.lm.1, MSE.lm.2, MSE.lm.3,
                      cv.err.loocv, cv.err.k.fold.10, cv.err.k.fold.5), 2),
          MSE = round(c(MSE.lm.1_1, MSE.lm.2_1, MSE.lm.3_1,
                      cv.err.loocv_1, cv.err.k.fold.10_1, cv.err.k.fold.5_1), 2))

# все модели по возрастанию ошибки
df.MSE[order(df.MSE$MSE), ]
```

Опираясь на результаты расчётов с кросс-валидацией, можно заключить, что на самом деле ошибка вне выборки у линейной модели выше, чем показывала MSE на тестовой выборке. В целом, ошибка методом проверочной выборки размером 50% от числа наблюдений занижает MSE и, следовательно, завышает точность моделей.

#Бутстреп

##Точность оценки параметра регрессии.

При построении модели регрессии проблемы в остатках приводят к неверной оценке ошибок параметров. Обойти эту проблему можно, применив для расчёта этих ошибок бутстреп.

```{r}
# функция для расчёта коэффициентов ПЛР по выборке из данных
boot.fn <- function(data, index){
  coef(lm(crim ~ chas, data = data, subset = index))
}
boot.fn(DF.Boston, 1:n)
```

# применениe функции к бутстреп-выборке

```{r}
set.seed(my.seed)
boot.fn(DF.Boston, sample(n, n, replace = T))
```

применяем функцию boot для вычисления стандартных ошибок параметров

```{r}
boot(DF.Boston, boot.fn, 1000)
```

сравним с ошибками параметров по МНК

```{r}
summary(fit.lm.1)$coef
summary(fit.lm.1_1)$coef
```

График остатков линейной модели

```{r}
plot(fit.lm.1, 3)
```


```{r}
boot.fn.2 <- function(data, index){
  coef(lm(crim ~ poly(zn, 2) + poly(rm, 2), data = data, subset = index))
}
# применим функцию к 1000 бутсреп-выборкам
set.seed(my.seed)
boot(DF.Boston, boot.fn.2, 1000)
```


```{r}
summary(fit.lm.2)$coef
summary(fit.lm.2_1)$coef
```

График остатков квадратичной модели

```{r}
plot(fit.lm.2, 3)
```

Нелинейность в остатках полинома третьей степени остаётся, и бутстреп-ошибки параметров модели выше, чем аналогичные МНК-оценки.


